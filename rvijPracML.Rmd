---
title: "rvijPracticalML sumitted for Coursera Practical ML"
author: "Rajeev Vij"
date: "July 20, 2014"
output: html_document
---

### Following steps will be used to apply ML to the given problem
* Load raw data into R data-frame
* Look at the summary of the data and check for data quality
* use any visualization techniques to understand data relationships
* Prepare clean tidy dataset for analysis
* Use caret package to divide dataset into training and validation set
* Apply different ML algorithms to training dataset and measure its accuracy
* Choose the best algorithm 
* Predict values for the chosen algorithm to the test dataset

### Load Data into R data-frame and run Summary
```{r}
library(caret); library(ggplot2)
set.seed(5469)

# Load the test file:
dataset  <- read.csv("../pml-training.csv", na.strings=c("NA",""), strip.white=TRUE)
dim(dataset)
dataset_test <- read.csv("../pml-testing.csv", na.strings=c("NA",""), strip.white=T)

# Check the summary of the data frame.
summary(dataset)

# There are large number of attributes that have NAs, we will ignore those variable as they may not contribute to 
# any predictive capability, also there are some time variables that will not be used

```

### Clean data and create a Tidy dataset

```{r}
createTidyDataset = function(data){
  # Cleaning the data:
  isNAcolumns <- apply(data, 2, function(x) { sum(is.na(x)) })
  
  tidyData <- subset(data[, which(isNAcolumns == 0)], 
                     select=-c(X, user_name, new_window, num_window, 
                               raw_timestamp_part_1, raw_timestamp_part_2, 
                               cvtd_timestamp))
}

dataset <- createTidyDataset(dataset)
  
dim(dataset)

dataset_test <- createTidyDataset(dataset_test)
dim(dataset_test)
```

### Create a training and validation dataset also create folds for 10-fold cross validation

```{r}
inTrain <- createDataPartition(dataset$classe, p=0.8, list=FALSE)
train_set <- dataset[inTrain,]
validation_set <- dataset[-inTrain,]

# Cross-Validation folds 
folds <- createFolds(y=dataset$classe,k=10, list=TRUE,returnTrain=TRUE)
sapply(folds,length)
```

```
## Test 1: Boosting classifier using cross validation contol
```{r}
ctrl <- trainControl(allowParallel=TRUE, method="cv")
bomodel <- train(classe ~ ., data=train_set, model="gbm", trControl=ctrl)
predictor <- predict(bomodel, newdata=validation_set)

# Error on valid_set:
sum(predictor == validation_set$classe) / length(predictor)
confusionMatrix(validation_set$classe, predictor)$table

# Classification for test_set:

predict(bomodel, newdata=dataset_test)
```

## Test 2: Random forest classifier using cross validation contol
```{r}
ctrl <- trainControl(allowParallel=TRUE, method="cv")
rfmodel <- train(classe ~ ., data=train_set, model="rf", trControl=ctrl)
predictor <- predict(rfmodel, newdata=validation_set)

# Error on valid_set:
sum(predictor == validation_set$classe) / length(predictor)
confusionMatrix(validation_set$classe, predictor)$table

# # Classification for test_set:
# 
predict(rfmodel, newdata=dataset_test)
```

## Both Random Forest and Boosting algorithm gives good results with > 99% cross validation accuracy.
## Random forest gives somewhat betetr results.
## However because of large number of variables and large dataset these models take some time to train
## We will now try SVM but on shorter list of variables.
## We will pick TopTen variables from Random Forest model and train an SVM on those variables only.
# Train the SVM on the dataset reduce to Top ten variables
```{r}
load("rfmodel.rda")
impvar <- varImp(rfmodel)

impvar$importance$var <- rownames(impvar$importance)

top10var <- impvar$importance[order(impvar$importance$Overall, decreasing = TRUE),c("var")][1:10]

dataset_topten <- subset(dataset, select=c(top10var, "classe"))

dataset_topten_test <- subset(dataset_test, select=c(top10var))

dataset_topten_test$classe <- NA

svm <- train(classe ~ ., data=dataset_topten[inTrain,], model="svm", trControl=ctrl)

predictor_svm <- predict(svm, newdata=validation_set)

sum(predictor_svm == validation_set$classe) / length(predictor_svm)
confusionMatrix(validation_set$classe, predictor_svm)$table

results <- predict(svm, newdata=dataset_topten_test)
```

## SVM on Top10 models has very good accuracy and is reasonably fast, we can use this model for implementaiton
##predicted values from SVM on test dataset are
```{r}
results
```

